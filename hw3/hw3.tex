\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\title{Homework 3}
\author{Steve Gillet}
\date{\today}

% Custom information
\newcommand{\className}{Course: Linear Control Design – ASEN 5014-001 – Fall 2024}
\newcommand{\professorName}{Professor: Dale Lawrence}
\newcommand{\taName}{Teaching Assistant: Karan Muvvala}

\begin{document}

% Title
\maketitle
\begin{center}
    \large{\className} \\
    \large{\professorName} \\
    \large{\taName}
\end{center}

\section{Question 1}
5.39 Consider $x_1$=$\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$
$x_2$=$\begin{bmatrix} 1 \\ -2 \\ 3 \end{bmatrix}$
$x_3$=$\begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix}$

(a) Show that this set is linearly independent.

(b) Generate an orthonormal set using the Gram-Schmidt procedure.

\subsection{Gram-Schmidt Orthonormal}

I can answer part 'a' of the question in the process of doing part 'b' (specifically by showing that none of thee orthonormal vectors are zero vectors) and so I will start with part 'b' and the Gram-Schmidt procedure.
\\
\\
\textbf{Finding Orthoganal Vectors:}

\begin{align}
    q_1 &= x_1=\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}\\
    q_2 &= x_2 - \left( \frac{x_2^T q_1}{q_1^T q_1} \right) q_1 \\
        &= \begin{bmatrix} 1 \\ -2 \\ 3 \end{bmatrix}-\left( \frac{\begin{bmatrix} 1 & -2 & 3 \end{bmatrix}\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}}{\begin{bmatrix} 1 & 2 & 3 \end{bmatrix}\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}} \right)\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}\\
        &= \begin{bmatrix} \frac{4}{7} \\ \frac{-20}{7} \\ \frac{12}{7} \end{bmatrix} \\
    q_3 &= x_3 - \left( \frac{x_3^T q_1}{q_1^T q_1} \right) q_1 - \left( \frac{x_3^T q_2}{q_2^T q_2} \right) q_2 \\
        &= \begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix} - \left( \frac{\begin{bmatrix} 0 & 1 & 1 \end{bmatrix}\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}}{\begin{bmatrix} 1 & 2 & 3 \end{bmatrix}\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}} \right)\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} - \left( \frac{\begin{bmatrix} 0 & 1 & 1 \end{bmatrix}\begin{bmatrix} \frac{4}{7} \\ \frac{-20}{7} \\ \frac{12}{7} \end{bmatrix}}{\begin{bmatrix} \frac{4}{7} & \frac{-20}{7} & \frac{12}{7} \end{bmatrix}\begin{bmatrix} \frac{4}{7} \\ \frac{-20}{7} \\ \frac{12}{7} \end{bmatrix}} \right)\begin{bmatrix} \frac{4}{7} \\ \frac{-20}{7} \\ \frac{12}{7} \end{bmatrix} \\
        &= \begin{bmatrix} \frac{-31}{70} \\ 0 \\ \frac{1}{10} \end{bmatrix}
\end{align}
$\uparrow$ None of these vectors are zero vectors answering 'part a' of the question. The set is linearly independent.

\textbf{Normalizing Vectors to Get Final Orthonormal Vectors:}

In order to normalize the orthogonal vectors we found we can divide them by their L2 norms.

$\hat{q_i} = \frac{q_i}{|q_i|}$

\begin{align}
    q_1 &= \begin{bmatrix} \frac{1}{\sqrt{14}} \\ \sqrt{\frac{2}{7}} \\ \frac{3}{\sqrt{14}} \end{bmatrix}\\
    q_2 &= \begin{bmatrix} \frac{1}{\sqrt{35}} \\ \sqrt{\frac{5}{7}} \\ \frac{3}{\sqrt{35}} \end{bmatrix} \\
    q_3 &= \begin{bmatrix} \frac{-31}{\sqrt{1010}} \\ 0 \\ \frac{7}{\sqrt{1010}} \end{bmatrix}
\end{align}

\section{Question 2}

Considering $x_1$, $x_2$, and $x_3$ of Problem 5.39 as a basis set, find the reciprocal basis set.

\subsection{Reciprocal Basis Set}

Given the vectors:
\[
\mathbf{x}_1 = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}, \quad
\mathbf{x}_2 = \begin{bmatrix} 1 \\ -2 \\ 3 \end{bmatrix}, \quad
\mathbf{x}_3 = \begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix}
\]
we want to find the reciprocal basis set \( \mathbf{x}^1, \mathbf{x}^2, \mathbf{x}^3 \).

The reciprocal basis vectors are computed using the formulas:
\[
\mathbf{x}^1 = \frac{\mathbf{x}_2 \times \mathbf{x}_3}{\mathbf{x}_1 \cdot (\mathbf{x}_2 \times \mathbf{x}_3)}, \quad
\mathbf{x}^2 = \frac{\mathbf{x}_3 \times \mathbf{x}_1}{\mathbf{x}_1 \cdot (\mathbf{x}_2 \times \mathbf{x}_3)}, \quad
\mathbf{x}^3 = \frac{\mathbf{x}_1 \times \mathbf{x}_2}{\mathbf{x}_1 \cdot (\mathbf{x}_2 \times \mathbf{x}_3)}
\]

First, we compute the cross products:
\[
\mathbf{x}_2 \times \mathbf{x}_3 = \begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
1 & -2 & 3 \\
0 & 1 & 1
\end{vmatrix}
= \begin{bmatrix} -5 \\ -1 \\ 1 \end{bmatrix}
\]
Now, compute the scalar:
\[
\mathbf{x}_1 \cdot (\mathbf{x}_2 \times \mathbf{x}_3) = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} \cdot \begin{bmatrix} -5 \\ -1 \\ 1 \end{bmatrix} = -4
\]

Thus, we compute the reciprocal basis vectors:
\[
\mathbf{x}^1 = \frac{1}{-4} \begin{bmatrix} -5 \\ -1 \\ 1 \end{bmatrix} = \begin{bmatrix} \frac{5}{4} \\ \frac{1}{4} \\ -\frac{1}{4} \end{bmatrix}
\]

Next:
\[
\mathbf{x}_3 \times \mathbf{x}_1 = \begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
0 & 1 & 1 \\
1 & 2 & 3
\end{vmatrix}
= \begin{bmatrix} 1 \\ 1 \\ -1 \end{bmatrix}
\]
\[
\mathbf{x}^2 = \frac{1}{-4} \begin{bmatrix} 1 \\ 1 \\ -1 \end{bmatrix} = \begin{bmatrix} -\frac{1}{4} \\ -\frac{1}{4} \\ \frac{1}{4} \end{bmatrix}
\]

Finally:
\[
\mathbf{x}_1 \times \mathbf{x}_2 = \begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
1 & 2 & 3 \\
1 & -2 & 3
\end{vmatrix}
= \begin{bmatrix} 12 \\ 0 \\ -4 \end{bmatrix}
\]
\[
\mathbf{x}^3 = \frac{1}{-4} \begin{bmatrix} 12 \\ 0 \\ -4 \end{bmatrix} = \begin{bmatrix} -3 \\ 0 \\ 1 \end{bmatrix}
\]

Thus, the reciprocal basis set is:
\[
\mathbf{x}^1 = \begin{bmatrix} \frac{5}{4} \\ \frac{1}{4} \\ -\frac{1}{4} \end{bmatrix}, \quad
\mathbf{x}^2 = \begin{bmatrix} -\frac{1}{4} \\ -\frac{1}{4} \\ \frac{1}{4} \end{bmatrix}, \quad
\mathbf{x}^3 = \begin{bmatrix} -3 \\ 0 \\ 1 \end{bmatrix}
\]

\section{Question 3}

Express the vector $z = \begin{bmatrix} 6 \\ 4 \\ -3 \end{bmatrix}$ in terms of the original basis set \{$x_i$\} of the Problem 5.39 by using the reciprocal basis vectors \{$r_i$\} found in Problem 5.40.

\subsection{z in Terms of Basis Set Using Reciprocal}

Given the vector:
\[
\mathbf{z} = \begin{bmatrix} 6 \\ 4 \\ -3 \end{bmatrix}
\]
we want to express \( \mathbf{z} \) in terms of the original basis vectors \( \mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3 \) from the previous problem. 

The relation is given by:
\[
\mathbf{z} = c_1 \mathbf{x}_1 + c_2 \mathbf{x}_2 + c_3 \mathbf{x}_3
\]
where the coefficients \( c_1, c_2, c_3 \) are found using the reciprocal basis vectors \( \mathbf{x}^1, \mathbf{x}^2, \mathbf{x}^3 \):
\[
c_1 = \mathbf{x}^1 \cdot \mathbf{z}, \quad c_2 = \mathbf{x}^2 \cdot \mathbf{z}, \quad c_3 = \mathbf{x}^3 \cdot \mathbf{z}
\]

From the previous problem, the reciprocal basis vectors are:
\[
\mathbf{x}^1 = \begin{bmatrix} \frac{5}{4} \\ \frac{1}{4} \\ -\frac{1}{4} \end{bmatrix}, \quad
\mathbf{x}^2 = \begin{bmatrix} -\frac{1}{4} \\ -\frac{1}{4} \\ \frac{1}{4} \end{bmatrix}, \quad
\mathbf{x}^3 = \begin{bmatrix} -3 \\ 0 \\ 1 \end{bmatrix}
\]

Now, we compute the coefficients:
\[
c_1 = \mathbf{x}^1 \cdot \mathbf{z} = \begin{bmatrix} \frac{5}{4} \\ \frac{1}{4} \\ -\frac{1}{4} \end{bmatrix} \cdot \begin{bmatrix} 6 \\ 4 \\ -3 \end{bmatrix} = \frac{5}{4}(6) + \frac{1}{4}(4) - \frac{1}{4}(-3) = 7.25
\]

\[
c_2 = \mathbf{x}^2 \cdot \mathbf{z} = \begin{bmatrix} -\frac{1}{4} \\ -\frac{1}{4} \\ \frac{1}{4} \end{bmatrix} \cdot \begin{bmatrix} 6 \\ 4 \\ -3 \end{bmatrix} = -\frac{1}{4}(6) - \frac{1}{4}(4) + \frac{1}{4}(-3) = -3.25
\]

\[
c_3 = \mathbf{x}^3 \cdot \mathbf{z} = \begin{bmatrix} -3 \\ 0 \\ 1 \end{bmatrix} \cdot \begin{bmatrix} 6 \\ 4 \\ -3 \end{bmatrix} = -3(6) + 0(4) + 1(-3) = -21
\]

Thus, the vector \( \mathbf{z} \) in terms of the original basis vectors is:
\[
\mathbf{z} = 7.25 \mathbf{x}_1 - 3.25 \mathbf{x}_2 - 21 \mathbf{x}_3
\]

\section{Question 4}

Compute the Grammian for the following vectors and draw conclusions about their linear independence. 

$y_1= \begin{bmatrix} 1.0000000E+00 \\ 1.0000000E+00 \\ 1.0000000E+00 \\ 1.0000000E+00 \end{bmatrix} y_2= \begin{bmatrix} 1.0001000E+00 \\ 9.9989998E-01 \\ 1.0000000E+00 \\ 1.0000000E+00 \end{bmatrix} y_3= \begin{bmatrix} -2.0000000E+00 \\ -1.9999000E+00 \\ -2.0000000E+00 \\ -2.0000000E+00 \end{bmatrix}$

\subsection{Grammian}

The Grammian matrix \( G \) is defined as:

\[
G = \begin{bmatrix} \mathbf{y}_1^T \mathbf{y}_1 & \mathbf{y}_1^T \mathbf{y}_2 & \mathbf{y}_1^T \mathbf{y}_3 \\
                    \mathbf{y}_2^T \mathbf{y}_1 & \mathbf{y}_2^T \mathbf{y}_2 & \mathbf{y}_2^T \mathbf{y}_3 \\
                    \mathbf{y}_3^T \mathbf{y}_1 & \mathbf{y}_3^T \mathbf{y}_2 & \mathbf{y}_3^T \mathbf{y}_3 \end{bmatrix}
\]

We calculate each element of the Grammian as follows:

\[
\mathbf{y}_1^T \mathbf{y}_1 = 1 \times 1 + 1 \times 1 + 1 \times 1 + 1 \times 1 = 4
\]

\[
\mathbf{y}_1^T \mathbf{y}_2 = 1 \times 1.0001 + 1 \times 9.9989998E-01 + 1 \times 1 + 1 \times 1 = 4.0000000E+00
\]

\[
\mathbf{y}_1^T \mathbf{y}_3 = 1 \times (-2) + 1 \times (-1.9999) + 1 \times (-2) + 1 \times (-2) = -7.9999
\]

\[
\mathbf{y}_2^T \mathbf{y}_2 = 1.0001 \times 1.0001 + 9.9989998E-01 \times 9.9989998E-01 + 1 \times 1 + 1 \times 1 = 4.0000002E+00
\]

\[
\mathbf{y}_2^T \mathbf{y}_3 = 1.0001 \times (-2) + 9.9989998E-01 \times (-1.9999) + 1 \times (-2) + 1 \times (-2) = -7.9998998
\]

\[
\mathbf{y}_3^T \mathbf{y}_3 = (-2) \times (-2) + (-1.9999) \times (-1.9999) + (-2) \times (-2) + (-2) \times (-2) = 15.99960001
\]

Thus, the Grammian matrix is:

\[
G = \begin{bmatrix}
4 & 4.0000000E+00 & -7.9999 \\
4.0000000E+00 & 4.0000002E+00 & -7.9998998 \\
-7.9999 & -7.9998998 & 15.99960001
\end{bmatrix}
\]

\subsection{Analyze the Grammian for Linear Independence}

For the set of vectors to be linearly independent, the Grammian matrix must be invertible, meaning its determinant must be non-zero. If the determinant of the Grammian is zero, the vectors are linearly dependent.

We can calculate the determinant of the matrix \( G \), and if \( \det(G) \neq 0 \), the vectors are linearly independent.

The determinant of the Grammian matrix is approximately 
$-1.54x10^{-13}$, which is very close to zero. This indicates that the vectors are linearly dependent.

\section{Question 5}

Determine the dimension of the vector space spanned by 

$x_1=\begin{bmatrix} 1 \\ 2 \\ 2 \\ 1 \end{bmatrix}, x_2=\begin{bmatrix} 1 \\ 0 \\ 0 \\ 1\end{bmatrix}, x_3= \begin{bmatrix} 3 \\ 4 \\ 4 \\ 3\end{bmatrix}$

\subsection{Form the Matrix}

We form the matrix \( A \) using the vectors as columns:

\[
A = \begin{bmatrix} 1 & 1 & 3 \\
                    2 & 0 & 4 \\
                    2 & 0 & 4 \\
                    1 & 1 & 3 \end{bmatrix}
\]

\subsection{Perform Row Reduction}

To determine the dimension of the vector space spanned by the columns of \( A \), we compute the rank of the matrix (the number of linearly independent columns).

1. Subtract 2 times the first row from the second and third rows and subtract the first row from the fourth row:

\[
A = \begin{bmatrix} 1 & 1 & 3 \\
                    0 & -2 & -2 \\
                    0 & -2 & -2 \\
                    0 & 0 & 0 \end{bmatrix}
\]

2. Add the second row to the third row:

\[
A = \begin{bmatrix} 1 & 1 & 3 \\
                    0 & -2 & -2 \\
                    0 & 0 & 0 \\
                    0 & 0 & 0 \end{bmatrix}
\]

After performing row reduction, we find that the matrix has rank 2. Hence, the dimension of the vector space spanned by \( \mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3 \) is 2.

\[
\text{Dimension} = 2
\]

Thus, the vectors span a 2-dimensional subspace of \( {R}^4 \).

\end{document}
